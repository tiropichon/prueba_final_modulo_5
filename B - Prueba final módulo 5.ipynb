{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a7a767",
   "metadata": {},
   "source": [
    "# B - Prueba final módulo 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f54ba",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "The Dogs vs. Cats dataset that you’ll use was made available by Kaggle as\n",
    "part of a computer-vision competition in late 2013. You’ll use it to train a\n",
    "convnet for image classification, getting as much accuracy as possible.\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "You can download the original dataset from here:\n",
    "\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "This dataset has around 25000 images of dogs and cats (12500 for each\n",
    "class), tagged by user in captcha tests provided from Asirra.\n",
    "We propose you to work only with 10% of the data. After downloading and\n",
    "uncompressing the data file, you’ll create a new dataset containing three\n",
    "subsets: a training set with 1,000 samples of each class, a validation set\n",
    "with 500 samples of each class, and a test set with 500 samples of each\n",
    "class.\n",
    "\n",
    "### CNN Building\n",
    "#### Task\n",
    "\n",
    "1. Explore the data and make the needed preprocessing the image dataset\n",
    "requires:\n",
    "a. Read the picture files.\n",
    "b. Decode the JPEG content to RGB grids of pixels.\n",
    "c. Convert these into floating-point tensors.\n",
    "d. Rescale the pixel values (between 0 and 255) to the [0, 1] interval\n",
    "\n",
    "2. Build a convnet as a stack of alternated Conv2D (with relu activation)\n",
    "and MaxPooling2D layers. Use the amount of each one that give you the\n",
    "best accuracy without time and memory over-penalization. End up with\n",
    "feature maps of size 7 x 7 just before the Flatten layer.\n",
    "\n",
    "3. Use the loss and optimizer you think better for image classification at\n",
    "the compiling step.\n",
    "\n",
    "4. Train the model displaying loss and accuracy curves during it.\n",
    "\n",
    "5. As you are working with few training samples, overfitting will be\n",
    "present. Use data augmentation (you can work with\n",
    "ImageDataGenerator instance in Keras) to avoid it.\n",
    "\n",
    "6. To further fight overfitting, you’ll also add a Dropout layer to your\n",
    "model, right before the densely connected classifier\n",
    "\n",
    "7. Save your model.\n",
    "\n",
    "8. To go further, we propose you to use a pre trained network: VGG16\n",
    "model developed by Karen Simonyan and Andrew Zisserman in 2014\n",
    "\n",
    "### Extra\n",
    "\n",
    "To go further, we propose you to use a pre trained network: the VGG16\n",
    "model developed by Karen Simonyan and Andrew Zisserman in 2014.\n",
    "Try applying feature extraction, importing keras.applications module,\n",
    "importing VGG16, instantiating the VGG16 convolutional base and using\n",
    "ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e7fe9",
   "metadata": {},
   "source": [
    "Cargamos las librerías para trabajar con numpy, pandas, matplotlib y keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400b8a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1621058175716,
     "user": {
      "displayName": "Mario Ruiz Ariza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwpOo7wLQysGamh5nCtU90J4zmWVRNA8ncv3huNw=s64",
      "userId": "06906307836671003182"
     },
     "user_tz": -120
    },
    "id": "6400b8a8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cargamos las librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c8efb",
   "metadata": {},
   "source": [
    "Importo la libreria zipfile, que sirve para extraer un archivo zip. Una vez que hemos descargado los archivos test1.zip y train.zip de la web de kaggle, en la carpeta /images, procedo a descomprimir su contenido. Tarda un poco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91da50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 892,
     "status": "error",
     "timestamp": 1621058265495,
     "user": {
      "displayName": "Mario Ruiz Ariza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwpOo7wLQysGamh5nCtU90J4zmWVRNA8ncv3huNw=s64",
      "userId": "06906307836671003182"
     },
     "user_tz": -120
    },
    "id": "da91da50",
    "outputId": "b5fda12d-4f20-4abf-e903-ba03ae5f3602"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('./images/test1.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./images')\n",
    "\n",
    "with zipfile.ZipFile('./images/train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b655f",
   "metadata": {},
   "source": [
    "Cargo con pandas, el csv de los datos de dogs vs. cats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06943e74",
   "metadata": {
    "id": "06943e74"
   },
   "outputs": [],
   "source": [
    "#Cargo con pandas, el csv de los datos de dogs vs. cats\n",
    "data = pd.read_csv(\"./csv/dogsvscats.csv\", header=None)\n",
    "#muestro los top 10 con las cabeceras\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb07de8",
   "metadata": {
    "id": "a96b6bad"
   },
   "source": [
    "Clasifico las imágenes de perros y gatos según el nombre del archivo, tanto en la carpeta 'train' como en la carpeta 'test1'. Una vez hecho esto, creo 3 datasets: uno para 'train', con 1000 imágenes de cada categoría; otro para 'valid', con 500 imágenes de cada categoría; finalmente otro para 'test', con 500 imágenes de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6353307",
   "metadata": {
    "id": "b6353307"
   },
   "outputs": [],
   "source": [
    "train_dir = './images/train'\n",
    "test_dir= './images/test1'\n",
    "\n",
    "train_dogs = ['./images/train/{}'.format(i) for i in os.listdir(train_dir) if 'dog' in i] #coge las imágenes de perros\n",
    "train_cats = ['./images/train/{}'.format(i) for i in os.listdir(train_dir) if 'cat' in i] #coge las imágenes de gatos\n",
    "\n",
    "test_dogs = ['./images/test1/{}'.format(i) for i in os.listdir(test_dir) if 'dog' in i] #coge las imágenes de perros\n",
    "test_cats = ['./images/test1/{}'.format(i) for i in os.listdir(test_dir) if 'cat' in i] #coge las imágenes de gatos\n",
    "\n",
    "train_img = train_dogs[:1000] + train_cats[:1000] #Slice dataset para training con 1000 datos de cada categoría.\n",
    "random.shuffle(train_img)\n",
    "valid_img = train_dogs[:500] + train_cats[:500] # Slice dataset validation con 500 cados de cada categoría\n",
    "random.shuffle(valid_img)\n",
    "test_img = test_dogs[:500] + test_cats[:500] #Slice dataset test con 500 casos de cada categoría\n",
    "random.shuffle(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daafefb",
   "metadata": {},
   "source": [
    "Visualizo las 3 primeras imágenes del dataset para 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671077c3",
   "metadata": {
    "id": "671077c3"
   },
   "outputs": [],
   "source": [
    "for img in train_img[0:3]:\n",
    "    img = mpimg.imread(img)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a583f",
   "metadata": {},
   "source": [
    "Redimensiono las imágenes a un tamaño de 150x150 pixels. Inicialmente el tamaño era de 250x250, pero a la hora de crear el feature map, el tamaño resultante era de 13x13, y no de 7x7 como pedía el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930dd7c",
   "metadata": {
    "id": "1930dd7c"
   },
   "outputs": [],
   "source": [
    "#resize de imagenes\n",
    "#inicialmente puse tamaño 250*250, pero la última capa terminaba\n",
    "#con tamaño 13x13 y no 7x7 como pedía el ejercicio\n",
    "nrows = 150\n",
    "ncols = 150\n",
    "channels = 3\n",
    "\n",
    "X = [] #imágenes\n",
    "y = [] #etiquetas\n",
    "\n",
    "for image in train_img:\n",
    "    X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows, ncols), interpolation=cv2.INTER_CUBIC)) #Lee la imagen\n",
    "    if 'dog' in image:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "        \n",
    "plt.figure(figsize=(20,10))\n",
    "columns=5\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(5/columns+1, columns, i+1)\n",
    "    imgplot = plt.imshow(X[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b3599",
   "metadata": {},
   "source": [
    "Convierto las listas en numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb0e07",
   "metadata": {
    "id": "4fdb0e07"
   },
   "outputs": [],
   "source": [
    "#convert lists in numpy arrays\n",
    "x = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "#print(\"shape de imágenes de training: \", X.shape)\n",
    "#print(\"shape de etiquetas: \",y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2a7e5",
   "metadata": {},
   "source": [
    "Genero los datos de train y test para el entrenamiento. Muestro el shape de cada una de las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d3d70",
   "metadata": {
    "id": "c23d3d70"
   },
   "outputs": [],
   "source": [
    "#split datos en training y validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Asigno el 20% de los datos para validación.\n",
    "X_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 2)\n",
    "\n",
    "print(\"shape X_train: \", X_train.shape)\n",
    "print(\"shape y_train: \",y_train.shape)\n",
    "print(\"shape x_test: \", x_test.shape)\n",
    "print(\"shape y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb22080",
   "metadata": {},
   "source": [
    "Muestro el nº de elementos de las variables de entrenamiento y test. 1600 elementos para entrenamiento y 400 elementos para test. Declaro una variable, con el valor que usaré para batch, que será 32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341c9bb",
   "metadata": {
    "id": "1341c9bb"
   },
   "outputs": [],
   "source": [
    "len_train = len(X_train)\n",
    "len_test = len(x_test)\n",
    "\n",
    "print(\"Nº de elementos de X_train: \",len_train)\n",
    "print(\"Nº de elementos de x_test: \",len_test)\n",
    "\n",
    "#Usaré un batch de 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e358c",
   "metadata": {},
   "source": [
    "Creo una red convolucional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c333fd",
   "metadata": {
    "id": "57c333fd"
   },
   "outputs": [],
   "source": [
    "#preparar la red convolucional\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9406a4",
   "metadata": {
    "id": "9a9406a4"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4623b6d",
   "metadata": {
    "id": "d4623b6d"
   },
   "outputs": [],
   "source": [
    "# metric = 'accuracy' pq es un problema de clasificación\n",
    "# loss = 'binary_crossentropy' pq estamos trabajando con 0 y 1\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=0.00001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9edfcad",
   "metadata": {
    "id": "b9edfcad"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "uso ImageDataGenerator() para convertir imágenes en tensors. Ésto ayuda a evitar overfitting\n",
    "Hace las siguientes tareas:\n",
    "1. Decodifica el contenido jpeg a rgb grids of pixels\n",
    "2. Convierte éstos en floating-point tensors\n",
    "3. Reescala los pixel values (entre 0 y 255) al intervalo [0,1]\n",
    "'''\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, #Reescala la imagen entre 0 y 1\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               zoom_range=0.2,shear_range= 0.2,\n",
    "                               horizontal_flip=True,)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25d4d3",
   "metadata": {
    "id": "9f25d4d3"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, y_train,batch_size=batch_size)\n",
    "val_generator = validation_datagen.flow(x_test, y_test,batch_size=batch_size)\n",
    "\n",
    "modelo = model.fit(train_generator,\n",
    "                   epochs=20,\n",
    "                   validation_data = val_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cd717",
   "metadata": {},
   "source": [
    "Muestro las curvas de accuracy y loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566cfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = modelo.history['acc']\n",
    "val_accuracy = modelo.history['val_acc']\n",
    "loss = modelo.history['loss']\n",
    "val_loss = modelo.history['val_loss']\n",
    "epochs = range(1, len(acc)+1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc,'r-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b-', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train-Validation-Accuracy-Curve')\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs,loss, 'r-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss,'b-', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train-Validation-loss-Curve')\n",
    "plt.legend()\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346eefb",
   "metadata": {},
   "source": [
    "Vamos a testear nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 150\n",
    "ncols = 150\n",
    "channels = 3\n",
    "\n",
    "X_test = [] #imágenes\n",
    "\n",
    "for image in train_img[0:10]:\n",
    "    X_test.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows, ncols), interpolation=cv2.INTER_CUBIC)) #Lee la imagen\n",
    "        \n",
    "x = np.array(X_test)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10231b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "text_labels = []\n",
    "plt.figure(figsize=(30,20))\n",
    "for batch in test_datagen.flow(x, batch_size=1):\n",
    "    pred = model.predict(batch)\n",
    "    if pred > 0.5:\n",
    "        text_labels.append('dog')\n",
    "    else:\n",
    "        text_labels.append('cat')\n",
    "    plt.subplot(5/columns+1, columns, i+1)\n",
    "    plt.title('This is a '+ text_labels[i])\n",
    "    imgplot = plt.imshow(batch[0])\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8ea36",
   "metadata": {},
   "source": [
    "Salvo el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e1dc4",
   "metadata": {
    "id": "709e1dc4"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save_weights('model_weights.h5')\n",
    "model.save('model_keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ddf36",
   "metadata": {
    "id": "0c3ddf36"
   },
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762d6d2",
   "metadata": {},
   "source": [
    "Genero los valores para train y validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6137a6",
   "metadata": {
    "id": "ad6137a6"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, y_train,batch_size=batch_size)\n",
    "val_generator = validation_datagen.flow(x_test, y_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c4333",
   "metadata": {},
   "source": [
    "Importo el modelo VGG16 de keras. Aplico como entrada, imágenes de 150x150. Preentreno el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509844f0",
   "metadata": {
    "id": "509844f0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Importamos desde el módulo aaplications al modelo VGG19 ya preentreado.\n",
    "VGG16_model = VGG16(input_shape=(150, 150, 3), weights=None, include_top=False, input_tensor=None, pooling=None)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# La parte convolucional de nuestra red será el modelo VGG16\n",
    "# preentrenado sobre el dataset Imagenet. Esta parte de la red\n",
    "# tendrá todos sus parámetros congelados.\n",
    "model.add(VGG16_model)\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64,  activation='relu'))\n",
    "model.add(layers.Dense(32,  activation='relu'))\n",
    "model.add(layers.Dense(16,  activation='relu'))\n",
    "model.add(layers.Dense(1,   activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.00001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9585d00",
   "metadata": {},
   "source": [
    "Presento un resumen del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535576b2",
   "metadata": {
    "id": "535576b2"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140b51a",
   "metadata": {},
   "source": [
    "Y ahora sí, entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a092e",
   "metadata": {
    "id": "6a0a092e"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "B - Prueba final módulo 5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
